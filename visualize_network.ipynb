{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Matrices and linear algebra fundamentals', 'K-Means Clustering', 'DBSCAN', 'HDBSCAN', 'Machine Learning']\n",
      "['Matrices and linear algebra fundamentals', 'Data mining', 'Machine Learning']\n"
     ]
    }
   ],
   "source": [
    "import rdflib\n",
    "import json\n",
    "\n",
    "# Load the ontology\n",
    "g = rdflib.Graph()\n",
    "g.parse(\"rdf/draft-topic-onto.rdf\")\n",
    "\n",
    "# Define start and end topics\n",
    "startID = \"Matrices and linear algebra fundamentals\"\n",
    "endID = \"Machine Learning\"\n",
    "\n",
    "# List to store the paths\n",
    "paths = []\n",
    "\n",
    "# Define the DFS function\n",
    "def DFS(stack, endID, path, paths):\n",
    "    if not stack:\n",
    "        DFS([startID] + stack, endID, path + [startID], paths)\n",
    "    else:\n",
    "        if path != [] and path[-1] == endID:\n",
    "            paths += [path]\n",
    "            return\n",
    "        \n",
    "        # Create a SPARQL query to find the next topics\n",
    "        sparql_query = f\"\"\"\n",
    "        PREFIX : <http://www.semanticweb.org/thuha/topic-onto/>\n",
    "        PREFIX owl: <http://www.w3.org/2002/07/owl#>\n",
    "        PREFIX rdf: <http://www.w3.org/1999/02/22-rdf-syntax-ns#>\n",
    "        PREFIX xml: <http://www.w3.org/XML/1998/namespace>\n",
    "        PREFIX xsd: <http://www.w3.org/2001/XMLSchema#>\n",
    "        PREFIX rdfs: <http://www.w3.org/2000/01/rdf-schema#>\n",
    "        PREFIX topics: <http://www.semanticweb.org/thuha/topic-onto#>\n",
    "        BASE <http://www.semanticweb.org/thuha/topic-onto/>\n",
    "        SELECT *\n",
    "        WHERE {{\n",
    "            ?start topics:topicID \"{stack[0]}\".\n",
    "            ?start topics:link ?topicID.\n",
    "        }}\n",
    "        \"\"\"\n",
    "\n",
    "        # Execute the SPARQL query\n",
    "        qres = g.query(sparql_query)\n",
    "        for row in qres:\n",
    "            DFS([row[\"topicID\"].value] + stack, endID, path + [row[\"topicID\"].value], paths)\n",
    "\n",
    "# Execute the DFS function to find paths\n",
    "DFS([], endID, [], paths)\n",
    "\n",
    "# Print the found paths\n",
    "for path in paths:\n",
    "    print(path)\n",
    "\n",
    "# Save the paths to a JSON file\n",
    "with open('paths.json', 'w') as json_file:\n",
    "    json.dump(paths, json_file, indent=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Matrices and linear algebra fundamentals': [(4, 0.7799999999999998, 'Document C')], 'K-Means Clustering': [], 'DBSCAN': [(3, 1.1599999999999997, 'Video B'), (5, 0.9799999999999999, 'Video A')], 'HDBSCAN': [], 'Machine Learning': [(2, 0.7799999999999998, 'Code C')]}\n",
      "Matrices and linear algebra fundamentals - Document C\n",
      "K-Means Clustering - 2\n",
      "DBSCAN - Video A\n",
      "HDBSCAN - Video C\n",
      "Machine Learning - Code C\n",
      "\n",
      "================================\n",
      "{'Matrices and linear algebra fundamentals': [(4, 0.7799999999999998, 'Document C')], 'Data mining': [], 'Machine Learning': [(2, 0.7799999999999998, 'Code C')]}\n",
      "Matrices and linear algebra fundamentals - Document C\n",
      "Data mining - Document D\n",
      "Machine Learning - Code C\n",
      "\n",
      "================================\n"
     ]
    }
   ],
   "source": [
    "import rdflib\n",
    "import json\n",
    "\n",
    "# Function to get learning materials based on topicID\n",
    "def getLMtopic(topicID):\n",
    "    sparql_query = f\"\"\"\n",
    "    PREFIX owl: <http://www.w3.org/2002/07/owl#>\n",
    "    PREFIX rdf: <http://www.w3.org/1999/02/22-rdf-syntax-ns#>\n",
    "    PREFIX xml: <http://www.w3.org/XML/1998/namespace>\n",
    "    PREFIX xsd: <http://www.w3.org/2001/XMLSchema#>\n",
    "    PREFIX rdfs: <http://www.w3.org/2000/01/rdf-schema#>\n",
    "    PREFIX onto: <http://www.semanticweb.org/thuha/ontologies/system-ontology#>\n",
    "    BASE <http://www.semanticweb.org/thuha/ontologies/system-ontology/>\n",
    "    SELECT *\n",
    "    WHERE {{\n",
    "        ?lm onto:topic \"{topicID}\".\n",
    "        ?lm onto:lmID ?lmID.\n",
    "        ?lm onto:material_ratings ?rating.\n",
    "        ?lm onto:score ?maxScore.\n",
    "        ?lm onto:time ?maxTime.\n",
    "        ?lm onto:difficulty ?difficulty.\n",
    "    }}\n",
    "    \"\"\"\n",
    "    qres = g.query(sparql_query)\n",
    "\n",
    "    lms = []\n",
    "    for row in qres:\n",
    "        #print(row[\"rating\"].value,row[\"lmID\"].value)\n",
    "        lms.append((row[\"rating\"].value, 0, row[\"lmID\"].value))\n",
    "\n",
    "    return lms\n",
    "\n",
    "# Load the ontology\n",
    "g = rdflib.Graph()\n",
    "g.parse(\"rdf/draft-system-onto.rdf\")\n",
    "\n",
    "qualification = \"Graduate\"\n",
    "backgroundKnowledge = \"Basic\"\n",
    "active_reflective = \"0\"\n",
    "visual_verbal = \"1\"\n",
    "global_sequential = \"1\"\n",
    "sensitive_intuitive = \"0\"\n",
    "\n",
    "sparql_query = f\"\"\"\n",
    "PREFIX owl: <http://www.w3.org/2002/07/owl#>\n",
    "PREFIX rdf: <http://www.w3.org/1999/02/22-rdf-syntax-ns#>\n",
    "PREFIX xml: <http://www.w3.org/XML/1998/namespace>\n",
    "PREFIX xsd: <http://www.w3.org/2001/XMLSchema#>\n",
    "PREFIX rdfs: <http://www.w3.org/2000/01/rdf-schema#>\n",
    "PREFIX onto: <http://www.semanticweb.org/thuha/ontologies/system-ontology#>\n",
    "BASE <http://www.semanticweb.org/thuha/ontologies/system-ontology/>\n",
    "SELECT *\n",
    "WHERE {{\n",
    "    ?learner onto:qualification \"{qualification}\".\n",
    "    ?learner onto:backgroundKnowledge \"{backgroundKnowledge}\".\n",
    "    ?learner onto:active_reflective \"{active_reflective}\"^^xsd:decimal.\n",
    "    ?learner onto:visual_verbal \"{visual_verbal}\"^^xsd:decimal.\n",
    "    ?learner onto:global_sequential \"{global_sequential}\"^^xsd:decimal.\n",
    "    ?learner onto:sensitive_intuitive \"{sensitive_intuitive}\"^^xsd:decimal.\n",
    "    ?learner onto:learnerID ?learnerID.\n",
    "    ?log onto:learnerID ?learnerID.\n",
    "    ?log onto:lmID ?lmID.\n",
    "    ?log onto:attempt ?attempt.\n",
    "    ?log onto:score ?score.\n",
    "    ?log onto:time ?time.\n",
    "    ?lm onto:lmID ?lmID.\n",
    "    ?lm onto:material_ratings ?rating.\n",
    "    ?lm onto:topic ?topicID.\n",
    "    ?lm onto:score ?maxScore.\n",
    "    ?lm onto:time ?maxTime.\n",
    "    ?lm onto:difficulty ?difficulty.\n",
    "}}\n",
    "\"\"\"\n",
    "qres = g.query(sparql_query)\n",
    "\n",
    "# with open('json/paths.json', 'r') as json_file:\n",
    "#     paths = json.load(json_file)\n",
    "\n",
    "paths = [\n",
    "    [\"Matrices and linear algebra fundamentals\",\"K-Means Clustering\",\"DBSCAN\",\"HDBSCAN\",\"Machine Learning\"],\n",
    "    [\"Matrices and linear algebra fundamentals\",\"Data mining\",\"Machine Learning\"]\n",
    "    ]\n",
    "for path in paths:\n",
    "    lms = {}\n",
    "    topics = {}\n",
    "    for topic in path:\n",
    "        topics[topic] = []\n",
    "    for row in qres:\n",
    "        #print('row_id: ',row[\"topicID\"].value)\n",
    "        if row[\"topicID\"].value not in topics:\n",
    "            continue\n",
    "\n",
    "        topicID = row[\"topicID\"].value\n",
    "        lmID = row[\"lmID\"].value\n",
    "        rating = int(row[\"rating\"].value)\n",
    "        #print(topicID, lmID, rating)\n",
    "        if lmID not in lms:\n",
    "            lms[lmID] = {\n",
    "                \"score\": float(row[\"score\"].value),\n",
    "                \"time\": float(row[\"time\"].value),\n",
    "                \"attempt\": int(row[\"attempt\"].value),\n",
    "                \"difficulty\": float(row[\"difficulty\"].value),\n",
    "                \"rating\": rating,\n",
    "                \"topic\": topicID,\n",
    "                \"maxScore\": float(row[\"maxScore\"].value),\n",
    "                \"maxTime\": float(row[\"maxTime\"].value),\n",
    "                \"repeat\": 1\n",
    "            }\n",
    "        else:\n",
    "            lms[lmID][\"score\"] += float(row[\"score\"].value)\n",
    "            lms[lmID][\"time\"] += float(row[\"time\"].value)\n",
    "            lms[lmID][\"attempt\"] += int(row[\"attempt\"].value)\n",
    "            lms[lmID][\"repeat\"] += 1\n",
    "    #print(lms)\n",
    "    for lm in lms:\n",
    "        aScore = lms[lm][\"score\"] / lms[lm][\"repeat\"]\n",
    "        aTime = lms[lm][\"time\"] / lms[lm][\"repeat\"]\n",
    "        aAttempt = lms[lm][\"attempt\"] / lms[lm][\"repeat\"]\n",
    "\n",
    "        similarity = abs(0.4 * (aScore / lms[lm][\"maxScore\"]) + 0.3 * (1.0 - aTime / lms[lm][\"maxTime\"]) + 0.3 * (1.0 - aAttempt) - lms[lm][\"difficulty\"])\n",
    "        topics[lms[lm][\"topic\"]].append((lms[lm][\"rating\"], similarity, lm))\n",
    "    print(topics)\n",
    "    for topic in topics:\n",
    "        if topics[topic] == []:\n",
    "            topics[topic] = getLMtopic(topic)\n",
    "        topics[topic].sort(key=lambda x: x[0], reverse=True)\n",
    "        end = round(len(topics[topic]) * 0.2 + 0.5)\n",
    "        topics[topic] = topics[topic][:end]\n",
    "        topics[topic].sort(key=lambda x: x[1])\n",
    "\n",
    "    for topic in topics:\n",
    "        \n",
    "        #print(topic)\n",
    "        print(str(topic) + \" - \" + topics[topic][0][2])\n",
    "\n",
    "    print(\"\\n================================\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matrices and linear algebra fundamentals,K-Means Clustering,DBSCAN,HDBSCAN,Machine Learning\n",
      "Matrices and linear algebra fundamentals,Data mining,Machine Learning\n"
     ]
    }
   ],
   "source": [
    "import rdflib\n",
    "import json\n",
    "\n",
    "class SpraqlTopic:\n",
    "    def __init__(self, startID, endID, path):\n",
    "        self.g = rdflib.Graph()\n",
    "        self.g.parse(path)\n",
    "        self.startID = startID\n",
    "        self.endID = endID\n",
    "    \n",
    "    def convertInt(self, value):\n",
    "        try:\n",
    "            return int(value)\n",
    "        except ValueError:\n",
    "            return value\n",
    "        \n",
    "    def DFS(self, stack, path, paths):\n",
    "        if not stack:\n",
    "            self.DFS([self.startID] + stack, path + [self.startID], paths)\n",
    "        else:\n",
    "            if path != [] and path[-1] == self.endID:\n",
    "                paths.append(path)  # Store path with string IDs\n",
    "                return\n",
    "            \n",
    "            sparql_query = f\"\"\"\n",
    "                PREFIX : <http://www.semanticweb.org/thuha/topic-onto/>\n",
    "                PREFIX owl: <http://www.w3.org/2002/07/owl#>\n",
    "                PREFIX rdf: <http://www.w3.org/1999/02/22-rdf-syntax-ns#>\n",
    "                PREFIX xml: <http://www.w3.org/XML/1998/namespace>\n",
    "                PREFIX rdfs: <http://www.w3.org/2000/01/rdf-schema#>\n",
    "                PREFIX topics: <http://www.semanticweb.org/thuha/topic-onto#>\n",
    "                BASE <http://www.semanticweb.org/thuha/topic-onto/>\n",
    "                SELECT ?topicID\n",
    "                WHERE\n",
    "                {{\n",
    "                    ?start topics:topicID \"{stack[0]}\".\n",
    "                    ?start topics:link ?topicID.\n",
    "                }}\n",
    "            \"\"\"\n",
    "            \n",
    "            qres = self.g.query(sparql_query)\n",
    "            for row in qres:\n",
    "                topic_id = row[\"topicID\"].value\n",
    "                converted_id = self.convertInt(topic_id)\n",
    "                if topic_id != 'None' and topic_id not in path:\n",
    "                    self.DFS([topic_id] + stack, path + [converted_id], paths)\n",
    "\n",
    "    def spraqlTopic(self):\n",
    "        paths = []\n",
    "        self.DFS([], [], paths)\n",
    "        with open('paths.json', 'w') as json_file:\n",
    "            json.dump(paths, json_file, indent=2)\n",
    "        return paths\n",
    "\n",
    "# Usage\n",
    "startID = \"Matrices and linear algebra fundamentals\"\n",
    "endID = \"Machine Learning\"\n",
    "rdf_path = \"rdf/draft-topic-onto.rdf\"\n",
    "\n",
    "spraql_topic = SpraqlTopic(startID, endID, rdf_path)\n",
    "paths = spraql_topic.spraqlTopic()\n",
    "\n",
    "# Print the paths\n",
    "for path in paths:\n",
    "    print(\",\".join(map(str, path)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "test",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
